{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 2 - Ames Housing Data and Kaggle Challenge\n",
    "\n",
    "_Authors: Patrick Wales-Dinan_\n",
    "\n",
    "---\n",
    "\n",
    "This lab was incredibly challenging. We had to extensively clean a date set that was missing a lot of values and had TONS of categorical data. Then we had to decide what features to use to model that data. After that we had to build and fit the models making decisions like whether to use polynomial features, dummy variables etc, log scaling features or log scaling the depended variable.\n",
    "\n",
    "After that we had to re run our model over and over again, looking at the different values of $\\beta$ and seeing if they were contributing to the predictive power of the model. We had to decide if we should throw those values out or if we should leave them. We also had to make judgement calls to see if our model appeared to be over fitting or suffering from bias. \n",
    "\n",
    "## Contents:\n",
    "- [Data Import](#Data-Import)\n",
    "- [Feature Creation](#Feature-Creation)\n",
    "- [Choosing the Features](#Feature-Choice)\n",
    "- [Log Scaling](#Log-Scaling-Independent-Variables)\n",
    "- [Cleaning the Data and Modifying the Data](#Cleaning-&-Creating-the-Data-Set)\n",
    "- [Modeling the Data](#Modeling-the-Data)\n",
    "- [Model Analysis](#Analyzing-the-model)\n",
    "\n",
    "Please visit the Graphs & Relationships notebook for additional visuals: Notebook - [Here](/Users/pwalesdi/Desktop/GA/GA_Project_2/Project_2_Graphs_&_Relationships.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.preprocessing import Imputer\n",
    "import math\n",
    "\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2051, 81)\n",
      "(879, 80)\n",
      "181469.70160897123\n"
     ]
    }
   ],
   "source": [
    "# Reading in the dataset\n",
    "ames_train = pd.read_csv('./datasets/train.csv')\n",
    "ames_test = pd.read_csv('./datasets/test.csv')\n",
    "ames_test_1 = pd.read_csv('./datasets/test.csv')\n",
    "ames_train_cate = ames_train.select_dtypes(include='object')\n",
    "ames_test_cate = ames_train.select_dtypes(include='object')\n",
    "test_id = ames_test['Id'].to_frame()\n",
    "Sale = (ames_train['SalePrice'])\n",
    "print(ames_train.shape)\n",
    "print(ames_test.shape)\n",
    "print(Sale.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculate the mean value relative to sale price of every categorical variable and replaces the \n",
    "# Corresponding levels with them ***NOTE*** it takes a long time to run as it has to iterate through every value of\n",
    "# Every level of every variable. Typically over an hour for each of the training and test dataset.\n",
    "Sale = (ames_train['SalePrice'])\n",
    "\n",
    "def mean_level(df, col, index):\n",
    "    mean = df.loc[df[col] == index]['SalePrice'].mean()\n",
    "    return mean\n",
    "\n",
    "def replace_with_sq_mean(df, col_list, inplace=True):\n",
    "    df2 = df.copy()\n",
    "    for col in col_list:\n",
    "        for (index, val) in df[col].iteritems():\n",
    "            mean = mean_level(df, col, val)\n",
    "            df2[col][index] = mean\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ames_train = replace_with_sq_mean(ames_train, ames_train_cate.columns)\n",
    "# ames_test['SalePrice'] = Sale\n",
    "# ames_test = replace_with_sq_mean(ames_test, ames_test_cate.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Creation this cell contains many different features that I created to test.\n",
    "ames_train['home_age'] = ames_train['Yr Sold'] - ames_train['Year Built']\n",
    "ames_test['home_age'] = ames_test['Yr Sold'] - ames_test['Year Built']\n",
    "ames_train['base_1st'] = ames_train['Total Bsmt SF'] * ames_train['1st Flr SF']\n",
    "ames_test['base_1st'] = ames_test['Total Bsmt SF'] * ames_test['1st Flr SF']\n",
    "ames_train['quality_age'] = ames_train['Overall Qual'] * ames_train['home_age']\n",
    "ames_test['quality_age'] = ames_test['Overall Qual'] * ames_test['home_age']\n",
    "ames_train['quality_sq_ft'] = ames_train['Overall Qual'] * ames_train['1st Flr SF']\n",
    "ames_test['quality_sq_ft'] = ames_test['Overall Qual'] * ames_test['1st Flr SF']\n",
    "ames_train['garage_area_cars'] = ames_train['Garage Area'] * ames_train['Garage Cars']\n",
    "ames_test['garage_area_cars'] = ames_test['Garage Area'] * ames_test['Garage Cars']\n",
    "ames_train['qual_neig'] = ames_train['Neighborhood'] * ames_train['Overall Qual']\n",
    "ames_test['qual_neig'] = ames_test['Neighborhood'] * ames_test['Overall Qual']\n",
    "ames_train['Quality_sq'] = ames_train['Overall Qual'] * ames_train['Overall Qual']\n",
    "ames_test['Quality_sq'] = ames_test['Overall Qual'] * ames_test['Overall Qual']\n",
    "ames_train['GLA_OQ'] = ames_train['Gr Liv Area'] * ames_train['Overall Qual']\n",
    "ames_test['GLA_OQ'] = ames_test['Gr Liv Area'] * ames_test['Overall Qual']\n",
    "ames_train['GLA_SQ'] = ames_train['Gr Liv Area'] * ames_train['Gr Liv Area']\n",
    "ames_test['GLA_SQ'] = ames_test['Gr Liv Area'] * ames_test['Gr Liv Area']\n",
    "ames_train['Yr_brm'] = ames_train['Year Built'] * ames_train['Year Remod/Add']\n",
    "ames_test['Yr_brm'] = ames_test['Year Built'] * ames_test['Year Remod/Add']\n",
    "ames_train['GLA_Bath'] = ames_train['Gr Liv Area'] * ames_train['Full Bath']\n",
    "ames_test['GLA_Bath'] = ames_test['Gr Liv Area'] * ames_test['Full Bath']\n",
    "ames_train['GLA_Garage'] = ames_train['Gr Liv Area'] * ames_train['garage_area_cars']\n",
    "ames_test['GLA_Garage'] = ames_test['Gr Liv Area'] * ames_test['garage_area_cars']\n",
    "ames_train['garage'] = ames_train['Garage Area'] > 0\n",
    "ames_test['garage'] = ames_test['Garage Area'] > 0\n",
    "ames_train['Qual_Gar'] = ames_train['Overall Qual'] * ames_train['garage']\n",
    "ames_test['Qual_Gar'] = ames_test['Overall Qual'] * ames_test['garage']\n",
    "ames_train['Qual_Liv_Gar'] = ames_train['Overall Qual'] * ames_train['Gr Liv Area'] * ames_train['Garage Area']\n",
    "ames_test['Qual_Liv_Gar'] = ames_test['Overall Qual'] * ames_test['Gr Liv Area'] * ames_test['Garage Area']\n",
    "ames_train['Qual*GLA*Lot'] = ames_train['Overall Qual'] * ames_train['Gr Liv Area'] * ames_train['Lot Area']\n",
    "ames_test['Qual*GLA*Lot'] = ames_test['Overall Qual'] * ames_test['Gr Liv Area'] * ames_test['Lot Area']\n",
    "# ames_test['Quality_rhood'] = ames_test['Overall Qual'] * ames_test['rich_hood']\n",
    "# ames_train['Quality_rhood'] = ames_train['Overall Qual'] * ames_train['rich_hood']\n",
    "# ames_test['Quality_phood'] = ames_test['Overall Qual'] * ames_test['poor_hood']\n",
    "# ames_train['Quality_phood'] = ames_train['Overall Qual'] * ames_train['poor_hood']\n",
    "# ames_test['Area_rhood'] = ames_test['Gr Liv Area'] * ames_test['rich_hood']\n",
    "# ames_train['Area_rhood'] = ames_train['Gr Liv Area'] * ames_train['rich_hood']\n",
    "# ames_test['EXTQUAL_GLA'] = ames_test['EX_Q'] * ames_test['Gr Liv Area']\n",
    "# ames_train['EXTQUAL_GLA'] = ames_train['EX_Q'] * ames_train['Gr Liv Area']\n",
    "# ames_test['Q_rhood'] = ames_test['Overall Qual'] * ames_test['rich_hood']\n",
    "# ames_train['Q_rhood'] = ames_train['Overall Qual'] * ames_train['rich_hood']\n",
    "ames_train['Total_Bath'] = ames_train['Full Bath'] + (0.5 * ames_train['Half Bath'])\n",
    "ames_test['Total_Bath'] = ames_test['Full Bath'] + (0.5 * ames_test['Half Bath'])\n",
    "ames_train['GLA_Bath'] = ames_train['Gr Liv Area'] * ames_train['Full Bath']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the NA numerical values with the mean or with no value reported\n",
    "ames_test.fillna(ames_test.mean(), inplace=True)\n",
    "ames_test.fillna('no_value_reported', inplace=True)\n",
    "\n",
    "# ames_train.fillna(ames_test.mean(), inplace=True)\n",
    "# ames_train.fillna('no_value_reported', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where I choose my variables to test.\n",
    "tested_col = [\n",
    "    'Overall Qual',\n",
    "    'Gr Liv Area',\n",
    "    'Full Bath',\n",
    "    'TotRms AbvGrd',\n",
    "    'GLA_OQ',\n",
    "    '1st Flr SF',\n",
    "    'Total Bsmt SF',\n",
    "#     'rich_hood',\n",
    "#     'garage',\n",
    "#     'Yr Sold',\n",
    "#     'Year Remod/Add',\n",
    "#     'Area_rhood',\n",
    "    'quality_sq_ft',\n",
    "#     'EX_Q',\n",
    "#     'GarageT',\n",
    "#     'HEAT',\n",
    "#     'BasQual',\n",
    "#     'FOUND',\n",
    "#     'ZONE',\n",
    "#     'Style',\n",
    "#     'home_age',\n",
    "#     'base_1st',\n",
    "  'Quality_sq',\n",
    "#     'GLA_SQ',\n",
    "    'GLA_Bath',\n",
    "#     'Quality_rhood',\n",
    "# ##    'qual_neig',\n",
    "#     'Qual*GLA*Lot',\n",
    "#     'Qual_Gar',\n",
    "#     'Qual_Liv_Gar',\n",
    "    'garage_area_cars',\n",
    "    'Yr_brm',\n",
    "#     'EXTQUAL_GLA',\n",
    "#     'GLA_Garage',\n",
    "#     'quality_age',\n",
    "##     'Roof_Sty',\n",
    "#     'EXTerior',\n",
    "#     'EXTcond',\n",
    "#     'MS SubClass',\n",
    "#     'MS Zoning', \n",
    "  'Street',\n",
    "##  'Alley', \n",
    "#   'Land Contour', \n",
    "#   'Lot Config', \n",
    "  'Neighborhood', \n",
    "#   'Condition 1',\n",
    "#     'Kitch_Qual',\n",
    "#     'Kitchen Qual',\n",
    "#   'Condition 2',\n",
    "  'Bldg Type',\n",
    "#   'House Style',\n",
    "#   'Exter Cond', \n",
    "#   'Heating', \n",
    "  'Exterior 1st',\n",
    "#   'Roof Style',\n",
    "#     'Lot Area',\n",
    "#     'Pool_Qual'\n",
    "    'Roof Matl',\n",
    "\n",
    "    \n",
    "    \n",
    "]         \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Scaling Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was used if I chose to log scale any of my independent variables. This didn't prove too useful so I didn't \n",
    "# use it very often. I left it however because it was included in some models.\n",
    "log_col = ['1st Flr SF',\n",
    "          'Gr Liv Area',\n",
    "          'TotRms AbvGrd',\n",
    "          'Year Built',\n",
    "          'GLA_SQ',\n",
    "          'quality_year',\n",
    "          'GLA_Bath']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that logs the independent variables that would be listed above\n",
    "def log_num_col(df, log_col, tested_col):\n",
    "    df_select = pd.DataFrame()\n",
    "    for col in tested_col:\n",
    "        if col not in log_col:\n",
    "            df_select = pd.concat([df_select, df[col]], axis=1)\n",
    "        else:\n",
    "            df_select[col] = df[col].apply(lambda x: math.log(x) if x != 0 else 0)\n",
    "    return df_select\n",
    "ames_train = log_num_col(ames_train, log_col, tested_col)\n",
    "ames_test = log_num_col(ames_test, log_col, tested_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is adding Sale Price back into our DF \n",
    "# ames_train = ames_train[tested_col]\n",
    "# ames_test = ames_test[tested_col]\n",
    "ames_train['SalePrice'] = Sale\n",
    "# ames_train.head()\n",
    "# ames_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning & Creating the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where all the magic happens\n",
    "def dropped_cols(df, tested_col): # This checks if the cols in the DF are not in the tested col list. If not it removes them.\n",
    "    dropped_col = []\n",
    "    for col in df:\n",
    "        if col not in tested_col:\n",
    "            dropped_col.append(col)\n",
    "    return dropped_col  \n",
    "\n",
    "\n",
    "def dummy_vars_list(df, tested_cols): # This is where the dummy variables list is created\n",
    "    dummy_vars_list = []\n",
    "    for col in tested_cols:\n",
    "        if df[col].dtype.name == 'object': # Checking to see if the col is labeled an object\n",
    "            dummy_vars_list.append(col)\n",
    "    return dummy_vars_list            \n",
    "\n",
    "\n",
    "def get_dummies(train, test, columns, drop_first=True,\n",
    "                inplace=False):\n",
    "    if not inplace:\n",
    "        train = copy.deepcopy(train)\n",
    "        test = copy.deepcopy(test)\n",
    "        \n",
    "\n",
    "    for column in columns:\n",
    "        train_levels = set(train[column])\n",
    "        test_levels = set(test[column])\n",
    "        all_levels = sorted(train_levels.union(test_levels))\n",
    "        if drop_first:\n",
    "            all_levels = all_levels[1:]\n",
    "        for level in all_levels:\n",
    "            dummy_name = \"%s_is_%s\" % (column, level) # Creating the dummy names for each level within a column\n",
    "            train[dummy_name] = (train[column] == level) # Could be replaced with an if statement\n",
    "            test[dummy_name] = (test[column] == level) # assigning those names to each of the dummy columns\n",
    "    train.drop(columns=columns, inplace=True) \n",
    "    test.drop(columns=columns, inplace=True)\n",
    "\n",
    "\n",
    "    # return only necessary if inplace=False\n",
    "    return (train, test)\n",
    "\n",
    "def check_compatibility(train, test):\n",
    "    # assume compatible unless one of these checks fails \n",
    "    if not (len(train.columns) == len(test.columns)):\n",
    "        return False\n",
    "    for column in train.columns:\n",
    "        if not (column in test.columns):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_data(train, test, columns_to_drop,\n",
    "               columns_for_dummies, remove_na=True,\n",
    "               drop_first=True, inplace=False):\n",
    "    if not inplace:\n",
    "        train = copy.deepcopy(train)\n",
    "        test = copy.deepcopy(test)\n",
    "  \n",
    "    # inplace=True because if user called with inplace=False,\n",
    "    # we already made a copy and aren't modifying his/her original\n",
    "    train.drop(columns=columns_to_drop, inplace=True)\n",
    "    test.drop(columns=columns_to_drop, inplace=True)\n",
    "  \n",
    "#     same reason as above for inplace=True\n",
    "    if remove_na:\n",
    "        train.dropna(inplace=True)\n",
    "        test.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    (train, test) = get_dummies(train, test,\n",
    "                                columns=columns_for_dummies,\n",
    "                                drop_first=drop_first,\n",
    "                                inplace=inplace)\n",
    "    \n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "###################\n",
    "# Here is where all of those functions get put into the master function that cleans and dummies the data\n",
    "def patrick_clean_data(train_df, test_df, variables, remove_na=True, drop_first=True, inplace=False):\n",
    "    columns_to_drop = dropped_cols(test_df, variables)\n",
    "    dummy_columns = dummy_vars_list(test_df, variables)\n",
    "    new_train, new_test = clean_data(train_df, test_df, \n",
    "                                     columns_to_drop, \n",
    "                                     dummy_columns, \n",
    "                                     remove_na=remove_na, \n",
    "                                     drop_first=drop_first, \n",
    "                                     inplace=inplace)\n",
    "# Here we are adding the Sale Price Column back into the DF\n",
    "    y_col_name = []\n",
    "    for col in new_train.columns:\n",
    "        if col not in new_test.columns:\n",
    "            y = new_train[col]\n",
    "            y_col_name = col\n",
    "    new_train = new_train.drop(y_col_name, axis=1)\n",
    "    \n",
    "    assert check_compatibility(new_train, new_test)\n",
    "    \n",
    "#     for column in new_test.columns: # Turn this on if I want to see what columns were made\n",
    "#         print(column)\n",
    "\n",
    "    return new_train, new_test, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(879, 66)\n",
      "(2049, 66)\n",
      "(2049,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train, new_test, y = patrick_clean_data(ames_train, ames_test, tested_col)\n",
    "print(new_test.shape)\n",
    "print(new_train.shape)\n",
    "print(y.shape)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function pretty much speaks for itself. It runs all of the regression, fits the models generated CV scores\n",
    "# and then returns the predictions for LASSO, Ridge and LR\n",
    "def metrics_summary(X, y, test_set, cv, k, scaled=True, poly=False, r_alpha=np.logspace(0, 5, 100), l_alpha=np.logspace(-3, 0, 100), log_y=True):\n",
    "    \n",
    "    if log_y:\n",
    "        np.log(y)\n",
    "        \n",
    "    # Run polynomial features\n",
    "    if poly:\n",
    "        poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "        X = poly.fit_transform(new_train)\n",
    "        test_set = poly.fit_transform(new_test)\n",
    "    \n",
    "    # Scaling our data\n",
    "    ss = StandardScaler()\n",
    "    X_sc = ss.fit_transform(X)\n",
    "    test_sc = ss.transform(test_set)\n",
    "\n",
    "    # Instantiating our models\n",
    "    model = LinearRegression()\n",
    "    lasso = LassoCV(alphas=l_alpha, max_iter=10_000, cv=7,)    \n",
    "    ridge = RidgeCV(alphas=r_alpha, cv=7)\n",
    "\n",
    "    # Fitting our models on non-scaled and scaled data\n",
    "    model.fit(X,y)\n",
    "    model.fit(X_sc, y)\n",
    "    lasso.fit(X_sc, y)\n",
    "    ridge.fit(X_sc, y)\n",
    "\n",
    "    # Running the predictions on our model\n",
    "    model_p = model.predict(X)\n",
    "    model_pred = model.predict(X_sc)\n",
    "    lasso_pred = lasso.predict(X_sc)\n",
    "    ridge_pred = ridge.predict(X_sc)\n",
    "\n",
    "    resids_lr = y - model_p\n",
    "    resids_lr_sc = y - model_pred\n",
    "    resids_lasso = y - lasso_pred\n",
    "    resids_ridge = y - ridge_pred\n",
    "\n",
    "    rss_lr = (resids_lr ** 2).sum()\n",
    "    rss_lr_sc = (resids_lr_sc ** 2).sum()\n",
    "    rss_lasso = (resids_lasso ** 2).sum()\n",
    "    rss_ridge = (resids_ridge ** 2).sum()\n",
    "\n",
    "    r_squared = (metrics.r2_score(y, model_p))\n",
    "    adj_r2 = 1 - (1-r_squared)*((len(y)-1)/(len(y)-X.shape[k]-1))\n",
    "\n",
    "    # Running cross value scores\n",
    "    cvs = cross_val_score(model, X_sc, y, cv=cv).mean()\n",
    "    cvs_l = cross_val_score(lasso, X_sc, y, cv=cv).mean()\n",
    "    cvs_r = cross_val_score(ridge, X_sc, y, cv=cv).mean()\n",
    "\n",
    "    print(f'RSS (Residual Sum of Squares) : {(rss_lr)}')\n",
    "    print(f'MAE (Mean Absolute Error) : {(metrics.mean_absolute_error(y, model_p))}') \n",
    "    print(f'MSE (Mean Square Error) : {(metrics.mean_squared_error(y, model_p))}')\n",
    "    print()\n",
    "    print(f'Root MSE (Root Meen Square Error Linear Non-Scaled) : {(np.sqrt(rss_lr / len(model_p)))}')\n",
    "    print(f'Root MSE (Root Meen Square Error Linear Scaled) : {(np.sqrt(rss_lr_sc / len(model_pred)))}')\n",
    "    print(f'Root MSE (Root Meen Square Error Lasso) : {(np.sqrt(rss_lasso / len(lasso_pred)))}')\n",
    "    print(f'Root MSE (Root Meen Square Error Ridge) : {(np.sqrt(rss_ridge / len(ridge_pred)))}')\n",
    "    print()\n",
    "    print(f'R\\u00b2 : {(r_squared)}')\n",
    "    print(f'Adjusted R\\u00b2 : {(adj_r2)}')\n",
    "    print()\n",
    "    print(f'CVS (Cross Value Score LR) : {(cvs)}')\n",
    "    print(f'CVS (Cross Value Score Lasso) : {(cvs_l)}')\n",
    "    print(f'CVS (Cross Value Score Ridge) : {(cvs_r)}')\n",
    "\n",
    "    model.fit(X_sc, y)\n",
    "    model_pred_final = model.predict(test_sc)\n",
    "    lasso.fit(X_sc, y)\n",
    "    lasso_pred_final = lasso.predict(test_sc)\n",
    "    ridge.fit(X_sc, y)\n",
    "    ridge_pred_final = ridge.predict(test_sc)\n",
    "\n",
    "    if (cvs > cvs_l) and (cvs > cvs_r):\n",
    "        prediction = pd.DataFrame({'Id': test_id['Id'], 'SalePrice': model_pred_final}).to_csv('wd_prediction_last.csv', index=False)\n",
    "    elif (cvs_l > cvs) and (cvs_l > cvs_r):\n",
    "        prediction = pd.DataFrame({'Id': test_id['Id'], 'SalePrice': lasso_pred_final}).to_csv('wd_prediction_last.csv', index=False)\n",
    "    elif (cvs_r > cvs_l) and (cvs_r > cvs):\n",
    "        prediction = pd.DataFrame({'Id': test_id['Id'], 'SalePrice': ridge_pred_final}).to_csv('wd_prediction_last.csv', index=False)\n",
    "    return prediction, ridge_pred_final, lasso_pred_final, model_pred_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The function takes 3 inputs, training a testing datafram and a dependent variable. It can run polynomial\n",
    "# features if need be and can log scale the dependent variable\n",
    "prediction, ridge, lasso, linear = metrics_summary(new_train, y, new_test, 5, 1, poly=False, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I need to exponentiate the predictions I do that outside of the funtion here and then apply to the dataframe\n",
    "# for submission. \n",
    "prediction_l2 = np.exp(ridge)\n",
    "prediction_lr = np.exp(linear)\n",
    "prediction_l1 = np.exp(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to create an output in order to view the coefficient of a LR, Ridge or Lasso regression for analysis.\n",
    "# You can view them below\n",
    "ss = StandardScaler()\n",
    "X_sc = ss.fit_transform(new_train)\n",
    "test_sc = ss.transform(new_test)\n",
    "model = LinearRegression()\n",
    "lasso = LassoCV(n_alphas=1000, cv=5)    \n",
    "ridge = RidgeCV(cv=5)\n",
    "model.fit(X_sc, y)\n",
    "lasso.fit(X_sc, y)\n",
    "ridge.fit(X_sc, y)\n",
    "model_pred = model.predict(X_sc)\n",
    "lasso_pred = lasso.predict(X_sc)\n",
    "ridge_pred = ridge.predict(X_sc)\n",
    "resids_lr_sc = y - model_pred\n",
    "resids_lasso = y - lasso_pred\n",
    "resids_ridge = y - ridge_pred\n",
    "new_train['Pred_Price'] = lasso_pred\n",
    "new_train['SalePrice'] = Sale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'variables':new_train.columns})\n",
    "print(lasso.coef_.shape)\n",
    "coe = pd.DataFrame({'ß - Beta':lasso.coef_})\n",
    "coef_df = pd.concat([coef_df, coe], axis=1)\n",
    "values = pd.DataFrame(new_train, index=list(range(0,2049)), columns=coef_df['variables'])\n",
    "values['SalePrice'] = Sale\n",
    "values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.sort_values('ß - Beta', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.corr()[['SalePrice']].sort_values('SalePrice', ascending=False).head(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a plot of the residuals of the ridge regression.\n",
    "ax = sns.scatterplot(x=ridge_pred, y=resids_ridge, palette='husl', ci=95);\n",
    "\n",
    "# # ax = sns.lmplot(x=\"Pred_Price\", y=\"SalePrice\", data=new_train, x_estimator=np.mean);\n",
    "# new_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
